{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L24 Channel Mix & Time Mix Quantized Training\n",
    "\n",
    "Starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_WANDB: True\n",
      "GPU_DEVICES: auto\n",
      "NOTEBOOK_DIR: /home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v6-layerNbits\n",
      "TRAINER_DIR: /home/recursal/RWKV-infctx-trainer/RWKV-v6-QT\n",
      "PROJECT_DIR: /home/recursal/RWKV-infctx-trainer\n"
     ]
    }
   ],
   "source": [
    "GPU_DEVICES=\"auto\"\n",
    "ENABLE_WANDB=True\n",
    "WANDB_PREFIX=\"XQT-\"\n",
    "\n",
    "print(\"ENABLE_WANDB:\", ENABLE_WANDB)\n",
    "print(\"GPU_DEVICES:\", GPU_DEVICES)\n",
    "\n",
    "if ENABLE_WANDB:\n",
    "    WANDB_MODE=\"online\"\n",
    "else:\n",
    "    WANDB_MODE=\"disabled\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v6-QT/\"))\n",
    "\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)\n",
    "\n",
    "# Baseline layer count, and embedding size\n",
    "L_SIZE=24\n",
    "D_SIZE=2048\n",
    "\n",
    "# Deepspeed and batch size\n",
    "DEEPSPEED_STAGE=\"deepspeed_stage_2\"\n",
    "BATCH_SIZE=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map (num_proc=160): 100%|â–ˆâ–ˆâ–ˆ| 1000000/1000000 [00:37<00:00, 26659.45 examples/s]\n",
      "Filter (num_proc=160): 100%|â–ˆ| 1000000/1000000 [00:06<00:00, 149382.73 examples/\n",
      "Map (num_proc=160): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 472276/472276 [00:24<00:00, 19407.40 examples/s]\n",
      "Map (num_proc=160): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 124119/124119 [00:20<00:00, 5977.08 examples/s]\n",
      "Saving the dataset (7/7 shards): 100%|â–ˆ| 124119/124119 [00:03<00:00, 39297.29 ex\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆ| 100/100 [00:00<00:00, 4449.34 examples/\n"
     ]
    }
   ],
   "source": [
    "# Lets preload the requried dataset \n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 preload_datapath.py \"{NOTEBOOK_DIR}/config/enwiki_100k-world-4k-rechunk.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-30 17:58:24,363] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : None (RKV)\n",
      "[RWKV] CMIX Quantize type    : None (RKV)\n",
      "====================================================================\n",
      "---- Initializing model ----\n",
      "No of layers: 24\n",
      "Embedding size: 2048\n",
      "Output model path: ../model/L24-D2048-world-v6base-init.pth\n",
      "Vocab size: 65536\n",
      "Emb scale: 0.0001\n",
      "Note: this process takes a significant time (and ram) for large models\n",
      "---- ----- ----\n",
      "Output model exists, skipping init_model\n",
      "-rw-rw-r-- 1 recursal recursal 3.0G Apr 21 13:45 /home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/../model/L24-D2048-world-v6base-init.pth\n"
     ]
    }
   ],
   "source": [
    "# Baseline layer count, and embedding size\n",
    "L_SIZE=24\n",
    "D_SIZE=2048\n",
    "\n",
    "# Init the model\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 ./init_model.py \\\n",
    "        --n_layer {L_SIZE} --n_embd {D_SIZE} \\\n",
    "        --vocab_size world --skip-if-exists \\\n",
    "        \"../model/L{L_SIZE}-D{D_SIZE}-world-v6base-init.pth\"\n",
    "!ls -lh \"{TRAINER_DIR}/../model/L{L_SIZE}-D{D_SIZE}-world-v6base-init.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L24-D2048 : Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: no process found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-05-01 12:49:36,275] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : None (RKV)\n",
      "[RWKV] CMIX Quantize type    : None (RKV)\n",
      "====================================================================\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py:518: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v6-layerNbits/config/enwiki_100k-world-32k-rechunk.yaml', '--model.load_model=../model/L24-D2048-world-v6base-init.pth', '--model.lr_init=3e-4', '--model.lr_final=3e-4', '--trainer.callbacks.init_args.dirpath=../checkpoint/v6-enwiki-100k-L24-D2048-LRI-3e-4-LRF-3e-4/', '--trainer.logger.init_args.name=REF-L24-D2048,LRI-3e-4,LRF-3e-4 (Rechunk 4k, deepspeed_stage_2)', '--trainer.strategy=deepspeed_stage_2', '--trainer.microbatch_size=4', '--trainer.devices=auto'], args=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v6-layerNbits/config/enwiki_100k-world-32k-rechunk.yaml', '--model.load_model=../model/L24-D2048-world-v6base-init.pth', '--model.lr_init=3e-4', '--model.lr_final=3e-4', '--trainer.callbacks.init_args.dirpath=../checkpoint/v6-enwiki-100k-L24-D2048-LRI-3e-4-LRF-3e-4/', '--trainer.logger.init_args.name=REF-L24-D2048,LRI-3e-4,LRF-3e-4 (Rechunk 4k, deepspeed_stage_2)', '--trainer.strategy=deepspeed_stage_2', '--trainer.microbatch_size=4', '--trainer.devices=auto'].\n",
      "Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       16\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             8\n",
      "   - microbatch_size:         4\n",
      "   - accumulate_grad_batches: 1\n",
      "   - effective_batch_size:    32\n",
      "\n",
      "[rank: 0] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "[2024-05-01 12:49:51,650] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 12:49:51,675] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 12:49:51,696] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 12:49:51,795] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 12:49:51,873] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 12:49:52,089] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 12:49:52,118] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : None (RKV)\n",
      "[RWKV] CMIX Quantize type    : None (RKV)\n",
      "====================================================================\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : None (RKV)\n",
      "[RWKV] CMIX Quantize type    : None (RKV)\n",
      "====================================================================\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : None (RKV)\n",
      "[RWKV] CMIX Quantize type    : None (RKV)\n",
      "====================================================================\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : None (RKV)\n",
      "[RWKV] CMIX Quantize type    : None (RKV)\n",
      "====================================================================\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : None (RKV)\n",
      "[RWKV] CMIX Quantize type    : None (RKV)\n",
      "====================================================================\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : None (RKV)\n",
      "[RWKV] CMIX Quantize type    : None (RKV)\n",
      "====================================================================\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : None (RKV)\n",
      "[RWKV] CMIX Quantize type    : None (RKV)\n",
      "====================================================================\n",
      "[rank: 3] Seed set to 3941088705\n",
      "[rank: 5] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 4] Seed set to 3941088705\n",
      "[rank: 2] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 6] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 7] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 1] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 3] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 4] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 5] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 6] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 2] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 1] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 7] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicocreator\u001b[0m (\u001b[33mrwkv-x-dev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240501_125039-0s5esc4g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mREF-L24-D2048,LRI-3e-4,LRF-3e-4 (Rechunk 4k, deepspeed_stage_2)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v6x-layerNbits\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v6x-layerNbits/runs/0s5esc4g\u001b[0m\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "#\n",
      "# RWKV lighting_trainer.py important notes \n",
      "# https://github.com/RWKV/RWKV-infctx-trainer \n",
      "#\n",
      "# - Ensure your host is not running cuda 12.0 (use either 11.8, or >=12.1), as this is known to have freeze issues\n",
      "# - The terms used in wandb / the progress bar can be confusing, see the github README.md for beter clarifications\n",
      "# - When resuming from checkpoint, the estimated time is inaccurate\n",
      "#\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  3.000e-04 (0.0003)\n",
      "    - lr_final: 3.000e-04 (0.0003)\n",
      "\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.06255006790161133 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.0666501522064209 seconds\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Time to load fused_adam op: 0.10230708122253418 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.07037782669067383 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.2019813060760498 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.20218777656555176 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.20250344276428223 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.20530176162719727 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 134 M \n",
      "1 | blocks | ModuleList | 1.3 B \n",
      "2 | ln_out | LayerNorm  | 4.1 K \n",
      "3 | head   | Linear     | 134 M \n",
      "--------------------------------------\n",
      "1.6 B     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 B     Total params\n",
      "6,399.492 Total estimated model params size (MB)\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:104: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "Epoch 0:  32%|â–Ž| 100/313 [1:15:43<2:41:17,  0.02it/s, v_num=sc4g, train/loss=5.6/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|â–ˆ| 313/313 [3:57:27<00:00,  0.02it/s, v_num=sc4g, train/loss=4.500`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Epoch 0: 100%|â–ˆ| 313/313 [3:57:27<00:00,  0.02it/s, v_num=sc4g, train/loss=4.500\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.034 MB of 0.042 MB uploaded (0.003 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   batchidx â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      epoch â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                global_rank â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: perf/kTokens_per_sec.gpu.0 â–ˆâ–…â–„â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   perf/kTokens_total.gpu.0 â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    substep â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/data_ctxlen â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/data_loss â–ˆâ–†â–†â–†â–…â–…â–„â–„â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           train/learn_loss â–ˆâ–†â–†â–†â–…â–…â–„â–„â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/learn_tokens â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/loss â–ˆâ–…â–ƒâ–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      trainer/learning_rate â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   batchidx 312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                global_rank 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: perf/kTokens_per_sec.gpu.0 2.88082\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   perf/kTokens_total.gpu.0 41025.536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    substep 2496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/data_ctxlen 32768.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/data_loss 4.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           train/learn_loss 4.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/learn_tokens 32768.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/loss 4.40625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        trainer/global_step 312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      trainer/learning_rate 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mREF-L24-D2048,LRI-3e-4,LRF-3e-4 (Rechunk 4k, deepspeed_stage_2)\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v6x-layerNbits/runs/0s5esc4g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ï¸âš¡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v6x-layerNbits/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE2NjU0ODg2Mw==/version_details/v8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240501_125039-0s5esc4g/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Learning rate setting\n",
    "LR_INIT=\"3e-4\"\n",
    "LR_FINAL=\"3e-4\"\n",
    "\n",
    "# Nuke python3 (for back to back run cleanup)\n",
    "!killall -9 python3\n",
    "\n",
    "# Run with the LRX setting\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python3 lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/config/enwiki_100k-world-32k-rechunk.yaml\" \\\n",
    "        --model.load_model=\"../model/L{L_SIZE}-D{D_SIZE}-world-v6base-init.pth\" \\\n",
    "        --model.lr_init=\"{LR_INIT}\" \\\n",
    "        --model.lr_final=\"{LR_FINAL}\" \\\n",
    "        --trainer.callbacks.init_args.dirpath=\"../checkpoint/v6-enwiki-100k-L{L_SIZE}-D{D_SIZE}-LRI-{LR_INIT}-LRF-{LR_FINAL}/\" \\\n",
    "        --trainer.logger.init_args.name=\"REF-L{L_SIZE}-D{D_SIZE},LRI-{LR_INIT},LRF-{LR_FINAL} (Rechunk 4k, {DEEPSPEED_STAGE})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STAGE}\" \\\n",
    "        --trainer.microbatch_size={BATCH_SIZE} \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C and R mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: no process found\n",
      "[2024-05-01 16:48:36,948] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py:518: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v6-layerNbits/config/enwiki_100k-world-32k-rechunk.yaml', '--model.load_model=../model/L24-D2048-world-v6base-init.pth', '--model.lr_init=3e-4', '--model.lr_final=3e-4', '--trainer.callbacks.init_args.dirpath=../checkpoint/v6-enwiki-100k-L24-D2048-TLR-1_RKV-CLR-4_RKV-Qnf4-TM_KV-CM_R/', '--trainer.logger.init_args.name=XQT-L24-D2048-TLR-1_RKV-CLR-4_RKV-Qnf4-TM_KV-CM_R (Rechunk 4k, deepspeed_stage_2)', '--trainer.strategy=deepspeed_stage_2', '--trainer.microbatch_size=4', '--trainer.devices=auto'], args=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v6-layerNbits/config/enwiki_100k-world-32k-rechunk.yaml', '--model.load_model=../model/L24-D2048-world-v6base-init.pth', '--model.lr_init=3e-4', '--model.lr_final=3e-4', '--trainer.callbacks.init_args.dirpath=../checkpoint/v6-enwiki-100k-L24-D2048-TLR-1_RKV-CLR-4_RKV-Qnf4-TM_KV-CM_R/', '--trainer.logger.init_args.name=XQT-L24-D2048-TLR-1_RKV-CLR-4_RKV-Qnf4-TM_KV-CM_R (Rechunk 4k, deepspeed_stage_2)', '--trainer.strategy=deepspeed_stage_2', '--trainer.microbatch_size=4', '--trainer.devices=auto'].\n",
      "Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       16\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             8\n",
      "   - microbatch_size:         4\n",
      "   - accumulate_grad_batches: 1\n",
      "   - effective_batch_size:    32\n",
      "\n",
      "[rank: 0] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "[2024-05-01 16:48:54,603] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:48:54,606] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:48:54,620] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:48:54,622] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:48:54,698] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:48:54,788] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:48:54,884] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "[rank: 2] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 6] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 3] Seed set to 3941088705\n",
      "[rank: 5] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 4] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 1] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 7] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 2] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 1] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 3] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 6] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 4] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 7] Seed set to 3941088705\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 5] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicocreator\u001b[0m (\u001b[33mrwkv-x-dev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240501_164943-wk6hzrqu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mXQT-L24-D2048-TLR-1_RKV-CLR-4_RKV-Qnf4-TM_KV-CM_R (Rechunk 4k, deepspeed_stage_2)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v6x-layerNbits\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v6x-layerNbits/runs/wk6hzrqu\u001b[0m\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "#\n",
      "# RWKV lighting_trainer.py important notes \n",
      "# https://github.com/RWKV/RWKV-infctx-trainer \n",
      "#\n",
      "# - Ensure your host is not running cuda 12.0 (use either 11.8, or >=12.1), as this is known to have freeze issues\n",
      "# - The terms used in wandb / the progress bar can be confusing, see the github README.md for beter clarifications\n",
      "# - When resuming from checkpoint, the estimated time is inaccurate\n",
      "#\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  3.000e-04 (0.0003)\n",
      "    - lr_final: 3.000e-04 (0.0003)\n",
      "\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.06681346893310547 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.07222485542297363 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.07233047485351562 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.1033782958984375 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.20258569717407227 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.08851075172424316 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.30228662490844727 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10228705406188965 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 134 M \n",
      "1 | blocks | ModuleList | 500 M \n",
      "2 | ln_out | LayerNorm  | 4.1 K \n",
      "3 | head   | Linear     | 134 M \n",
      "--------------------------------------\n",
      "769 M     Trainable params\n",
      "0         Non-trainable params\n",
      "769 M     Total params\n",
      "3,077.603 Total estimated model params size (MB)\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:104: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "Epoch 0:   0%|                                          | 0/313 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 295, in _forward_nocuda_optimized\n",
      "    w = torch.exp(-torch.exp(w))\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 3 has a total capacty of 23.65 GiB of which 5.81 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 91.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 295, in _forward_nocuda_optimized\n",
      "    w = torch.exp(-torch.exp(w))\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 6 has a total capacty of 23.65 GiB of which 5.81 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 91.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^Traceback (most recent call last):\n",
      "^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 295, in _forward_nocuda_optimized\n",
      "    cli_main()\n",
      "    w = torch.exp(-torch.exp(w))\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "        ^^^^^^^^^^^^^^^^^^    ^LightningCLI(^\n",
      "^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 5 has a total capacty of 23.65 GiB of which 5.81 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 91.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 295, in _forward_nocuda_optimized\n",
      "    w = torch.exp(-torch.exp(w))\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 4 has a total capacty of 23.65 GiB of which 5.81 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 91.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 295, in _forward_nocuda_optimized\n",
      "    w = torch.exp(-torch.exp(w))\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 7 has a total capacty of 23.65 GiB of which 5.81 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 91.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 295, in _forward_nocuda_optimized\n",
      "    w = torch.exp(-torch.exp(w))\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 2 has a total capacty of 23.65 GiB of which 5.81 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 91.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 295, in _forward_nocuda_optimized\n",
      "    w = torch.exp(-torch.exp(w))\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 5.81 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 91.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 295, in _forward_nocuda_optimized\n",
      "    w = torch.exp(-torch.exp(w))\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB. GPU 1 has a total capacty of 23.65 GiB of which 5.81 MiB is free. Including non-PyTorch memory, this process has 23.64 GiB memory in use. Of the allocated memory 22.97 GiB is allocated by PyTorch, and 91.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "[rank: 1] Child process with PID 1386304 terminated with code 1. Forcefully terminating all other processes to avoid zombies ðŸ§Ÿ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mXQT-L24-D2048-TLR-1_RKV-CLR-4_RKV-Qnf4-TM_KV-CM_R (Rechunk 4k, deepspeed_stage_2)\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v6x-layerNbits/runs/wk6hzrqu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ï¸âš¡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v6x-layerNbits/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE2NjU0ODg2Mw==/version_details/v9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240501_164943-wk6hzrqu/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Learning rate setting\n",
    "LR_INIT=\"3e-4\"\n",
    "LR_FINAL=\"3e-4\"\n",
    "\n",
    "# Channel and timemix quantized settings\n",
    "RWKV_CMIX_QTYPE=\"nf4\"\n",
    "RWKV_TIMX_QTYPE=\"nf4\"\n",
    "\n",
    "# mix quantized vars\n",
    "RWKV_CMIX_QVARS=\"R\"\n",
    "RWKV_TMIX_QVARS=\"KV\"\n",
    "\n",
    "RWKV_CMIX_REUSE_MULTIPLIER=\"4\"\n",
    "RWKV_CMIX_REUSE_VARS=\"RKV\"\n",
    "\n",
    "RWKV_TMIX_REUSE_MULTIPLIER=\"1\"\n",
    "RWKV_TMIX_REUSE_VARS=\"RKV\"\n",
    "\n",
    "# Nuke python3 (for back to back run cleanup)\n",
    "!killall -9 python3\n",
    "\n",
    "# Run the training\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    export RWKV_JIT_ON=\"0\" && \\\n",
    "    export RWKV_TORCH_COMPILE=\"0\" && \\\n",
    "    export RWKV_CMIX_QTYPE=\"{RWKV_CMIX_QTYPE}\" && \\\n",
    "    export RWKV_TIMX_QTYPE=\"{RWKV_TIMX_QTYPE}\" && \\\n",
    "    export RWKV_CMIX_QVARS=\"{RWKV_CMIX_QVARS}\" && \\\n",
    "    export RWKV_TMIX_QVARS=\"{RWKV_TMIX_QVARS}\" && \\\n",
    "    export RWKV_TMIX_REUSE_MULTIPLIER=\"{RWKV_TMIX_REUSE_MULTIPLIER}\" && \\\n",
    "    export RWKV_CMIX_REUSE_MULTIPLIER=\"{RWKV_CMIX_REUSE_MULTIPLIER}\" && \\\n",
    "    export RWKV_CMIX_REUSE_VARS=\"{RWKV_CMIX_REUSE_VARS}\" && \\\n",
    "    export RWKV_TMIX_REUSE_VARS=\"{RWKV_TMIX_REUSE_VARS}\" && \\\n",
    "    python3 lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/config/enwiki_100k-world-32k-rechunk.yaml\" \\\n",
    "        --model.load_model=\"../model/L{L_SIZE}-D{D_SIZE}-world-v6base-init.pth\" \\\n",
    "        --model.lr_init=\"{LR_INIT}\" \\\n",
    "        --model.lr_final=\"{LR_FINAL}\" \\\n",
    "        --trainer.callbacks.init_args.dirpath=\"../checkpoint/v6-enwiki-100k-L{L_SIZE}-D{D_SIZE}-TLR-{RWKV_TMIX_REUSE_MULTIPLIER}_{RWKV_TMIX_REUSE_VARS}-CLR-{RWKV_CMIX_REUSE_MULTIPLIER}_{RWKV_CMIX_REUSE_VARS}-Q{RWKV_TIMX_QTYPE}-TM_{RWKV_TMIX_QVARS}-CM_{RWKV_CMIX_QVARS}/\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX}L{L_SIZE}-D{D_SIZE}-TLR-{RWKV_TMIX_REUSE_MULTIPLIER}_{RWKV_TMIX_REUSE_VARS}-CLR-{RWKV_CMIX_REUSE_MULTIPLIER}_{RWKV_CMIX_REUSE_VARS}-Q{RWKV_TIMX_QTYPE}-TM_{RWKV_TMIX_QVARS}-CM_{RWKV_CMIX_QVARS} (Rechunk 4k, {DEEPSPEED_STAGE})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STAGE}\" \\\n",
    "        --trainer.microbatch_size={BATCH_SIZE} \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: no process found\n",
      "[2024-05-01 16:50:06,070] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py:518: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v6-layerNbits/config/enwiki_100k-world-32k-rechunk.yaml', '--model.load_model=../model/L24-D2048-world-v6base-init.pth', '--model.lr_init=3e-4', '--model.lr_final=3e-4', '--trainer.callbacks.init_args.dirpath=../checkpoint/v6-enwiki-100k-L24-D2048-TLR-4_RKV-CLR-1_RKV-Qnf4-TM_KV-CM_R/', '--trainer.logger.init_args.name=XQT-L24-D2048-TLR-4_RKV-CLR-1_RKV-Qnf4-TM_KV-CM_R (Rechunk 4k, deepspeed_stage_2)', '--trainer.strategy=deepspeed_stage_2', '--trainer.microbatch_size=4', '--trainer.devices=auto'], args=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/rwkv-x-exp/v6-layerNbits/config/enwiki_100k-world-32k-rechunk.yaml', '--model.load_model=../model/L24-D2048-world-v6base-init.pth', '--model.lr_init=3e-4', '--model.lr_final=3e-4', '--trainer.callbacks.init_args.dirpath=../checkpoint/v6-enwiki-100k-L24-D2048-TLR-4_RKV-CLR-1_RKV-Qnf4-TM_KV-CM_R/', '--trainer.logger.init_args.name=XQT-L24-D2048-TLR-4_RKV-CLR-1_RKV-Qnf4-TM_KV-CM_R (Rechunk 4k, deepspeed_stage_2)', '--trainer.strategy=deepspeed_stage_2', '--trainer.microbatch_size=4', '--trainer.devices=auto'].\n",
      "Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       16\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             8\n",
      "   - microbatch_size:         4\n",
      "   - accumulate_grad_batches: 1\n",
      "   - effective_batch_size:    32\n",
      "\n",
      "[rank: 0] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "[2024-05-01 16:50:22,733] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:50:22,750] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:50:22,750] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:50:22,819] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:50:22,945] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:50:22,989] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-05-01 16:50:23,066] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "[RWKV.model] Running RWKV infctx using 'torch-native' with torch '2.1.2'\n",
      "====================================================================\n",
      "[RWKV] TMIX reuse multiplier : 4 (RKV)\n",
      "[RWKV] CMIX reuse multiplier : 1 (RKV)\n",
      "[RWKV] TMIX Quantize type    : nf4 (KV)\n",
      "[RWKV] CMIX Quantize type    : nf4 (R)\n",
      "====================================================================\n",
      "[rank: 4] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 2] Seed set to 3941088705\n",
      "[rank: 6] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 3] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 5] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 1] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 7] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 2] Seed set to 3941088705\n",
      "[rank: 5] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      ">> Loading dataset from data_path: >> Loading dataset from data_path:   ../datapath/enwiki_100k-world-32k-rechunk/../datapath/enwiki_100k-world-32k-rechunk/\n",
      "\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 4] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 6] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 7] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 3] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 1] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicocreator\u001b[0m (\u001b[33mrwkv-x-dev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240501_165110-feymmw5e\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mXQT-L24-D2048-TLR-4_RKV-CLR-1_RKV-Qnf4-TM_KV-CM_R (Rechunk 4k, deepspeed_stage_2)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v6x-layerNbits\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-v6x-layerNbits/runs/feymmw5e\u001b[0m\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "#\n",
      "# RWKV lighting_trainer.py important notes \n",
      "# https://github.com/RWKV/RWKV-infctx-trainer \n",
      "#\n",
      "# - Ensure your host is not running cuda 12.0 (use either 11.8, or >=12.1), as this is known to have freeze issues\n",
      "# - The terms used in wandb / the progress bar can be confusing, see the github README.md for beter clarifications\n",
      "# - When resuming from checkpoint, the estimated time is inaccurate\n",
      "#\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  3.000e-04 (0.0003)\n",
      "    - lr_final: 3.000e-04 (0.0003)\n",
      "\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.06711530685424805 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.06428313255310059 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.06619763374328613 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10176873207092285 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10179758071899414 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.20513033866882324 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10214924812316895 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10497069358825684 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 134 M \n",
      "1 | blocks | ModuleList | 953 M \n",
      "2 | ln_out | LayerNorm  | 4.1 K \n",
      "3 | head   | Linear     | 134 M \n",
      "--------------------------------------\n",
      "1.2 B     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 B     Total params\n",
      "4,889.543 Total estimated model params size (MB)\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:104: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "Epoch 0:   0%|                                          | 0/313 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 278, in _forward_nocuda_optimized\n",
      "    xxx = torch.bmm(xxx, self.time_maa_w2).view(5, B, T, -1)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 320.00 MiB. GPU 1 has a total capacty of 23.65 GiB of which 95.81 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 171.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 278, in _forward_nocuda_optimized\n",
      "    xxx = torch.bmm(xxx, self.time_maa_w2).view(5, B, T, -1)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 320.00 MiB. GPU 7 has a total capacty of 23.65 GiB of which 95.81 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 171.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 278, in _forward_nocuda_optimized\n",
      "    xxx = torch.bmm(xxx, self.time_maa_w2).view(5, B, T, -1)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 320.00 MiB. GPU 4 has a total capacty of 23.65 GiB of which 95.81 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 171.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 278, in _forward_nocuda_optimized\n",
      "    xxx = torch.bmm(xxx, self.time_maa_w2).view(5, B, T, -1)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 320.00 MiB. GPU 6 has a total capacty of 23.65 GiB of which 95.81 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 171.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 278, in _forward_nocuda_optimized\n",
      "    xxx = torch.bmm(xxx, self.time_maa_w2).view(5, B, T, -1)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 320.00 MiB. GPU 3 has a total capacty of 23.65 GiB of which 95.81 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 171.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^Traceback (most recent call last):\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "   File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "          ^^^^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "^^^^^^^^^^^^^^^^^^^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "             File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "^^^^^^^^^^^^^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "^^^^^^^^^^^^^^^^^^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "           ^^^^^^^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "    out = method(*_args, **_kwargs)  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "            File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "              File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "              File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ret_val = func(*args, **kwargs)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "              ^^^^^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^^  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 278, in _forward_nocuda_optimized\n",
      "    xxx = torch.bmm(xxx, self.time_maa_w2).view(5, B, T, -1)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 320.00 MiB. GPU 0 has a total capacty of 23.65 GiB of which 95.81 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 171.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 278, in _forward_nocuda_optimized\n",
      "    xxx = torch.bmm(xxx, self.time_maa_w2).view(5, B, T, -1)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 320.00 MiB. GPU 5 has a total capacty of 23.65 GiB of which 31.81 MiB is free. Including non-PyTorch memory, this process has 23.61 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 235.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1381, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 1241, in compute_loss\n",
      "    self.manual_backward(learning_loss, optimizer, retain_graph=True)\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 850, in manual_backward\n",
      "    self.trainer.strategy.backward(loss, None, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 204, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 112, in backward\n",
      "    deepspeed_engine.backward(tensor, *args, **kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1955, in backward\n",
      "    self.optimizer.backward(loss, retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/zero/stage_1_and_2.py\", line 2019, in backward\n",
      "    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py\", line 63, in backward\n",
      "    scaled_loss.backward(retain_graph=retain_graph)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 674, in backward\n",
      "    outputs = ctx.run_function(*detached_inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 167, in blockset_forward\n",
      "    output_x, new_state_arr[i] = block_arr[i](output_x, last_state_arr[i])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/model.py\", line 101, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 211, in forward\n",
      "    return self._forward_nocuda_optimized(x, last_state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6-QT/src/module/TimeMix.py\", line 278, in _forward_nocuda_optimized\n",
      "    xxx = torch.bmm(xxx, self.time_maa_w2).view(5, B, T, -1)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 320.00 MiB. GPU 2 has a total capacty of 23.65 GiB of which 95.81 MiB is free. Including non-PyTorch memory, this process has 23.55 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 171.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "[rank: 1] Child process with PID 1389422 terminated with code 1. Forcefully terminating all other processes to avoid zombies ðŸ§Ÿ\n"
     ]
    }
   ],
   "source": [
    "# Learning rate setting\n",
    "LR_INIT=\"3e-4\"\n",
    "LR_FINAL=\"3e-4\"\n",
    "\n",
    "# Channel and timemix quantized settings\n",
    "RWKV_CMIX_QTYPE=\"nf4\"\n",
    "RWKV_TIMX_QTYPE=\"nf4\"\n",
    "\n",
    "# mix quantized vars\n",
    "RWKV_CMIX_QVARS=\"R\"\n",
    "RWKV_TMIX_QVARS=\"KV\"\n",
    "\n",
    "RWKV_CMIX_REUSE_MULTIPLIER=\"1\"\n",
    "RWKV_CMIX_REUSE_VARS=\"RKV\"\n",
    "\n",
    "RWKV_TMIX_REUSE_MULTIPLIER=\"4\"\n",
    "RWKV_TMIX_REUSE_VARS=\"RKV\"\n",
    "\n",
    "# Nuke python3 (for back to back run cleanup)\n",
    "!killall -9 python3\n",
    "\n",
    "# Run the training\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    export RWKV_JIT_ON=\"0\" && \\\n",
    "    export RWKV_TORCH_COMPILE=\"0\" && \\\n",
    "    export RWKV_CMIX_QTYPE=\"{RWKV_CMIX_QTYPE}\" && \\\n",
    "    export RWKV_TIMX_QTYPE=\"{RWKV_TIMX_QTYPE}\" && \\\n",
    "    export RWKV_CMIX_QVARS=\"{RWKV_CMIX_QVARS}\" && \\\n",
    "    export RWKV_TMIX_QVARS=\"{RWKV_TMIX_QVARS}\" && \\\n",
    "    export RWKV_TMIX_REUSE_MULTIPLIER=\"{RWKV_TMIX_REUSE_MULTIPLIER}\" && \\\n",
    "    export RWKV_CMIX_REUSE_MULTIPLIER=\"{RWKV_CMIX_REUSE_MULTIPLIER}\" && \\\n",
    "    export RWKV_CMIX_REUSE_VARS=\"{RWKV_CMIX_REUSE_VARS}\" && \\\n",
    "    export RWKV_TMIX_REUSE_VARS=\"{RWKV_TMIX_REUSE_VARS}\" && \\\n",
    "    python3 lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/config/enwiki_100k-world-32k-rechunk.yaml\" \\\n",
    "        --model.load_model=\"../model/L{L_SIZE}-D{D_SIZE}-world-v6base-init.pth\" \\\n",
    "        --model.lr_init=\"{LR_INIT}\" \\\n",
    "        --model.lr_final=\"{LR_FINAL}\" \\\n",
    "        --trainer.callbacks.init_args.dirpath=\"../checkpoint/v6-enwiki-100k-L{L_SIZE}-D{D_SIZE}-TLR-{RWKV_TMIX_REUSE_MULTIPLIER}_{RWKV_TMIX_REUSE_VARS}-CLR-{RWKV_CMIX_REUSE_MULTIPLIER}_{RWKV_CMIX_REUSE_VARS}-Q{RWKV_TIMX_QTYPE}-TM_{RWKV_TMIX_QVARS}-CM_{RWKV_CMIX_QVARS}/\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX}L{L_SIZE}-D{D_SIZE}-TLR-{RWKV_TMIX_REUSE_MULTIPLIER}_{RWKV_TMIX_REUSE_VARS}-CLR-{RWKV_CMIX_REUSE_MULTIPLIER}_{RWKV_CMIX_REUSE_VARS}-Q{RWKV_TIMX_QTYPE}-TM_{RWKV_TMIX_QVARS}-CM_{RWKV_CMIX_QVARS} (Rechunk 4k, {DEEPSPEED_STAGE})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STAGE}\" \\\n",
    "        --trainer.microbatch_size={BATCH_SIZE} \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv-infctx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
