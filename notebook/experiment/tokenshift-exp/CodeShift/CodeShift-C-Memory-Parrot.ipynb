{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RWKV CodeParrot + Memory tune\n",
    "This model is a custom model containing\n",
    "- 24 layers\n",
    "- 2048 embedding size\n",
    "\n",
    "And follows up on the memory tuned 4 model, and applies code training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File â€˜TokenShift-C-Tune4.pthâ€™ already there; not retrieving.\n",
      "\n",
      "-rw-r--r-- 1 root root 5.7G Jul 23 04:43 ../../../../model/TokenShift-C-Tune4.pth\n"
     ]
    }
   ],
   "source": [
    "# First lets setup the various directories, and get the model we need\n",
    "!mkdir -p ../../../../model/\n",
    "!mkdir -p ../../../../datapath/\n",
    "!mkdir -p ../../../../checkpoint/\n",
    "!cd ../../../../model/ && wget -nc https://huggingface.co/picocreator/memory-size-experiment-for-rwkv/resolve/main/TokenShift-C-Tune4.pth\n",
    "!ls -alh ../../../../model/TokenShift-C-Tune4.pth\n",
    "\n",
    "# The various other stages, if you want to skip stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEEPSPEED_STRAT: deepspeed_stage_1\n",
      "ENABLE_WANDB: True\n",
      "GPU_DEVICES: [0,1,2,3]\n",
      "NOTEBOOK_DIR: /root/rwkv5x-tokenshift-exp-A/notebook/experiment/tokenshift-exp/CodeShift\n",
      "INFERENCE_DIR: /root/rwkv5x-tokenshift-exp-A/RWKV-v4wavenet\n",
      "TRAINER_DIR: /root/rwkv5x-tokenshift-exp-A/RWKV-v4wavenet\n",
      "PROJECT_DIR: /root/rwkv5x-tokenshift-exp-A\n"
     ]
    }
   ],
   "source": [
    "DEEPSPEED_STRAT=\"deepspeed_stage_1\"\n",
    "GPU_DEVICES=\"[0,1,2,3]\"\n",
    "ENABLE_WANDB=True\n",
    "WANDB_PREFIX=\"CodeShift-C\"\n",
    "\n",
    "print(\"DEEPSPEED_STRAT:\", DEEPSPEED_STRAT)\n",
    "print(\"ENABLE_WANDB:\", ENABLE_WANDB)\n",
    "print(\"GPU_DEVICES:\", GPU_DEVICES)\n",
    "\n",
    "if ENABLE_WANDB:\n",
    "    WANDB_MODE=\"online\"\n",
    "else:\n",
    "    WANDB_MODE=\"disabled\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v4wavenet/\"))\n",
    "INFERENCE_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v4wavenet/\"))\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"INFERENCE_DIR:\", INFERENCE_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CodeParrot training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/root/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-fb728533b9673c8b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.20s/it]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Lets preload the requried dataset\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 preload_datapath.py \"{NOTEBOOK_DIR}/CodeShift-C-Memory-Parrot.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "/usr/local/lib/python3.11/dist-packages/lightning/fabric/utilities/seed.py:39: UserWarning: No seed found, seed set to 1110430979\n",
      "  rank_zero_warn(f\"No seed found, seed set to {seed}\")\n",
      "Global seed set to 1110430979\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicocreator\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20230727_065713-k89xyo4y\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mCodeShift-C - Memory-Parrot (ctx=4096, deepspeed_stage_1)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/picocreator/RWKV-5X-Experiments\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/picocreator/RWKV-5X-Experiments/runs/k89xyo4y\u001b[0m\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Creating extension directory /root/.cache/torch_extensions/py311_cu118/wkv_4096_bf16...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_4096_bf16/build.ninja...\n",
      "Building extension module wkv_4096_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=wkv_4096_bf16 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -t 4 -std=c++17 -res-usage --maxrregcount 60 --use_fast_math -O3 -Xptxas -O3 --extra-device-vectorization -DTmax=4096 -c /root/rwkv5x-tokenshift-exp-A/RWKV-v4wavenet/cuda/wkv_cuda_bf16.cu -o wkv_cuda_bf16.cuda.o \n",
      "ptxas info    : 1 bytes gmem\n",
      "ptxas info    : Compiling entry function '_Z15kernel_backwardiiiPKfPKN3c108BFloat16ES4_S4_S0_S4_S0_PS2_S5_S5_S5_Pf' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z15kernel_backwardiiiPKfPKN3c108BFloat16ES4_S4_S0_S4_S0_PS2_S5_S5_S5_Pf\n",
      "    49152 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 56 registers, 464 bytes cmem[0], 8 bytes cmem[2]\n",
      "ptxas info    : Compiling entry function '_Z14kernel_forwardiiiPKfPKN3c108BFloat16ES4_S4_S0_PS2_Pf' for 'sm_86'\n",
      "ptxas info    : Function properties for _Z14kernel_forwardiiiPKfPKN3c108BFloat16ES4_S4_S0_PS2_Pf\n",
      "    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads\n",
      "ptxas info    : Used 40 registers, 424 bytes cmem[0]\n",
      "[2/3] c++ -MMD -MF wkv_op_bf16.o.d -DTORCH_EXTENSION_NAME=wkv_4096_bf16 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -std=c++17 -O3 -DTmax=4096 -c /root/rwkv5x-tokenshift-exp-A/RWKV-v4wavenet/cuda/wkv_op_bf16.cpp -o wkv_op_bf16.o \n",
      "[3/3] c++ wkv_op_bf16.o wkv_cuda_bf16.cuda.o -shared -L/usr/local/lib/python3.11/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o wkv_4096_bf16.so\n",
      "Loading extension module wkv_4096_bf16...\n",
      "/usr/local/lib/python3.11/dist-packages/lightning/fabric/connector.py:562: UserWarning: bf16 is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       256\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             4\n",
      "   - accumulate_grad_batches: 64\n",
      "   - effective_batch_size:    256\n",
      "\n",
      "Found cached dataset json (/root/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-fb728533b9673c8b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]Setting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "[rank: 1] Global seed set to 1110430979\n",
      "[rank: 2] Global seed set to 1110430979\n",
      "[rank: 3] Global seed set to 1110430979\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.20s/it]\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_4096_bf16/build.ninja...\n",
      "Building extension module wkv_4096_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading extension module wkv_4096_bf16...\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-fb728533b9673c8b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-9d6348bc4c266814_*_of_00064.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-fb728533b9673c8b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-3008d203338f8d48_*_of_00064.arrow\n",
      "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-fb728533b9673c8b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-61554dc5c12fa1f7.arrow and /root/.cache/huggingface/datasets/codeparrot___json/codeparrot--codeparrot-clean-fb728533b9673c8b/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-992e5186abe1ea00.arrow\n",
      "Saving the dataset (10/194 shards):   5%| | 282980/5334566 [00:10<04:59, 16861.1[rank: 1] Global seed set to 1110430979\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/4\n",
      "[2023-07-27 06:58:04,884] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 2] Global seed set to 1110430979\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/4\n",
      "[2023-07-27 06:58:04,976] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 3] Global seed set to 1110430979\n",
      "Saving the dataset (10/194 shards):   5%| | 288980/5334566 [00:10<03:49, 21943.0initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/4\n",
      "[2023-07-27 06:58:04,995] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "[rank: 0] Global seed set to 1110430979                                         \n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/4\n",
      "[2023-07-27 07:01:33,306] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented\n",
      "Enabling DeepSpeed BF16.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  4.000e-04 (0.0004)\n",
      "    - lr_final: 1.000e-04 (0.0001)\n",
      "\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Creating extension directory /root/.cache/torch_extensions/py311_cu118/fused_adam...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/3] c++ -MMD -MF fused_adam_frontend.o.d -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/adam -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -DBF16_AVAILABLE -c /usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/adam/fused_adam_frontend.cpp -o fused_adam_frontend.o \n",
      "[2/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=fused_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/includes -I/usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/adam -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DVERSION_GE_1_5 -lineinfo --use_fast_math -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -DBF16_AVAILABLE -std=c++17 -c /usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/adam/multi_tensor_adam.cu -o multi_tensor_adam.cuda.o \n",
      "[3/3] c++ fused_adam_frontend.o multi_tensor_adam.cuda.o -shared -L/usr/local/lib/python3.11/dist-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o fused_adam.so\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 23.753950595855713 seconds\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 23.830382823944092 seconds\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 23.83539128303528 seconds\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 23.837732791900635 seconds\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Creating extension directory /root/.cache/torch_extensions/py311_cu118/utils...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /usr/local/lib/python3.11/dist-packages/torch/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -isystem /usr/local/lib/python3.11/dist-packages/torch/include/TH -isystem /usr/local/lib/python3.11/dist-packages/torch/include/THC -isystem /usr/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /usr/local/lib/python3.11/dist-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o \n",
      "[2/2] c++ flatten_unflatten.o -shared -L/usr/local/lib/python3.11/dist-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 11.527958869934082 seconds\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 11.614153146743774 seconds\n",
      "Time to load utils op: 11.613960266113281 seconds\n",
      "Time to load utils op: 11.616572380065918 seconds\n",
      "Rank: 2 partition count [4, 4, 4] and sizes[(378752000, False), (12288, False), (12288, False)] \n",
      "Rank: 0 partition count [4, 4, 4] and sizes[(378752000, False), (12288, False), (12288, False)] \n",
      "Rank: 1 partition count [4, 4, 4] and sizes[(378752000, False), (12288, False), (12288, False)] \n",
      "Rank: 3 partition count [4, 4, 4] and sizes[(378752000, False), (12288, False), (12288, False)] \n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0002605915069580078 seconds\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.00032806396484375 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0002651214599609375 seconds\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0004909038543701172 seconds\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 102 M \n",
      "1 | blocks | ModuleList | 1.3 B \n",
      "2 | ln_out | LayerNorm  | 4.1 K \n",
      "3 | head   | Linear     | 102 M \n",
      "--------------------------------------\n",
      "1.5 B     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 B     Total params\n",
      "6,060.425 Total estimated model params size (MB)\n",
      "Epoch 0:   1%| | 10514/1333642 [2:19:27<292:30:33,  1.26it/s, v_num=yo4y, train/\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ReadTimeout), entering retry loop.\n",
      "Epoch 0:   1%| | 16000/1333642 [3:33:32<293:05:25,  1.25it/s, v_num=yo4y, train//usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Epoch 0:  15%|â–| 198911/1333642 [44:14:51<252:25:11,  1.25it/s, v_num=yo4y, trai^C\n"
     ]
    }
   ],
   "source": [
    "# Start the foundation model training\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/CodeShift-C-Memory-Parrot.yaml\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} - Memory-Parrot (ctx=4096, {DEEPSPEED_STRAT})\" \\\n",
    "        --trainer.strategy=\"{DEEPSPEED_STRAT}\" \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Processing zero checkpoint '../checkpoint/CodeShift-C-Memory-Parrot/last.ckpt/checkpoint'\n",
      "Detected checkpoint of type zero stage ZeroStageEnum.optimizer_states, world_size: 4\n",
      "Parsing checkpoint created by deepspeed==0.9.3\n",
      "Reconstructed fp32 state dict with 438 params 1515106304 elements\n",
      "Saving fp32 state dict to ../model/CodeShift-C-Memory-Parrot.pth\n",
      "-rw-r--r-- 1 root root 5.7G Jul 29 03:18 ../model/CodeShift-C-Memory-Parrot.pth\n"
     ]
    }
   ],
   "source": [
    "# Lets export the model from the checkpoint\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python export_checkpoint.py \"../checkpoint/CodeShift-C-Memory-Parrot/last.ckpt\" \"../model/CodeShift-C-Memory-Parrot.pth\"\n",
    "!cd \"{TRAINER_DIR}\" && ls -alh \"../model/CodeShift-C-Memory-Parrot.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_1024_bf16/build.ninja...\n",
      "Building extension module wkv_1024_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_1024_bf16...\n",
      "--- DRAGON PROMPT ---\n",
      "In a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese. Let's look at the danger of being on the beach to \n",
      "find what he's being a zombie and then set the space on the lands, the territory we are seeing. After the rice returned in the jungle, \n",
      "it is true to be the lucky god, and in the meantime it is a good place to not be able to read the non-visible mountains in the \n",
      "wood area. That's the example that we were looking at, in the case of a swamp that does not stay in the territory.\n",
      "\n",
      "How many centuries has we ever seen at the time of placing a crown into one of the years?\n",
      "\n",
      "# In[1]:\n",
      "\n",
      "you are standing in a while, so if the first time, I was tempted to walk through the valley, and there's a problem\n",
      "and you have never tried to walk on the valley. Try:\n",
      "    - If the river reach into a valley, the river needs to reach a certain point, and\n"
     ]
    }
   ],
   "source": [
    "# # Lets do a quick dragon prompt validation\n",
    "!cd \"{INFERENCE_DIR}\" && python3 dragon_test.py ../model/CodeShift-C-Memory-Parrot.pth \"cuda fp32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.0.1+cu118'\n",
      "Using /root/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py311_cu118/wkv_1024_bf16/build.ninja...\n",
      "Building extension module wkv_1024_bf16...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module wkv_1024_bf16...\n",
      "###\n",
      "### Model validation start ###\n",
      "###\n",
      "## Model validation for 5 tokens : 40.0% similarity, with 2 matched token, and 3 token mismatch\n",
      "## Model validation for 10 tokens : 30.0% similarity, with 3 matched token, and 7 token mismatch\n",
      "## Model validation for 15 tokens : 13.333333333333334% similarity, with 2 matched token, and 13 token mismatch\n",
      "## Model validation for 20 tokens : 15.0% similarity, with 3 matched token, and 17 token mismatch\n",
      "## Model validation for 25 tokens : 12.0% similarity, with 3 matched token, and 22 token mismatch\n",
      "## Model validation for 30 tokens : 10.0% similarity, with 3 matched token, and 27 token mismatch\n",
      "## Model validation for 35 tokens : 8.571428571428571% similarity, with 3 matched token, and 32 token mismatch\n",
      "## Model validation for 40 tokens : 7.5% similarity, with 3 matched token, and 37 token mismatch\n",
      "## Model validation for 45 tokens : 6.666666666666667% similarity, with 3 matched token, and 42 token mismatch\n",
      "## Model validation for 50 tokens : 6.0% similarity, with 3 matched token, and 47 token mismatch\n",
      "## Model validation for 55 tokens : 5.454545454545454% similarity, with 3 matched token, and 52 token mismatch\n",
      "## Model validation for 60 tokens : 5.0% similarity, with 3 matched token, and 57 token mismatch\n",
      "## Model validation for 65 tokens : 4.615384615384616% similarity, with 3 matched token, and 62 token mismatch\n",
      "## Model validation for 70 tokens : 4.285714285714286% similarity, with 3 matched token, and 67 token mismatch\n",
      "## Model validation for 75 tokens : 4.0% similarity, with 3 matched token, and 72 token mismatch\n",
      "## Model validation for 80 tokens : 3.75% similarity, with 3 matched token, and 77 token mismatch\n",
      "## Model validation for 85 tokens : 2.3529411764705883% similarity, with 2 matched token, and 83 token mismatch\n",
      "## Model validation for 90 tokens : 3.3333333333333335% similarity, with 3 matched token, and 87 token mismatch\n",
      "## Model validation for 95 tokens : 5.263157894736842% similarity, with 5 matched token, and 90 token mismatch\n",
      "## Model validation for 100 tokens : 4.0% similarity, with 4 matched token, and 96 token mismatch\n",
      "## Model validation for 105 tokens : 3.8095238095238098% similarity, with 4 matched token, and 101 token mismatch\n",
      "## Model validation for 110 tokens : 1.8181818181818181% similarity, with 2 matched token, and 108 token mismatch\n",
      "## Model validation for 115 tokens : 3.4782608695652173% similarity, with 4 matched token, and 111 token mismatch\n",
      "## Model validation for 120 tokens : 3.3333333333333335% similarity, with 4 matched token, and 116 token mismatch\n",
      "## Model validation for 125 tokens : 2.4% similarity, with 3 matched token, and 122 token mismatch\n",
      "## Model validation for 130 tokens : 2.307692307692308% similarity, with 3 matched token, and 127 token mismatch\n",
      "## Model validation for 135 tokens : 2.2222222222222223% similarity, with 3 matched token, and 132 token mismatch\n",
      "## Model validation for 140 tokens : 2.142857142857143% similarity, with 3 matched token, and 137 token mismatch\n",
      "## Model validation for 145 tokens : 3.4482758620689653% similarity, with 5 matched token, and 140 token mismatch\n",
      "## Model validation for 150 tokens : 2.666666666666667% similarity, with 4 matched token, and 146 token mismatch\n",
      "## Model validation for 160 tokens : 2.5% similarity, with 4 matched token, and 156 token mismatch\n",
      "## Model validation for 170 tokens : 2.3529411764705883% similarity, with 4 matched token, and 166 token mismatch\n",
      "## Model validation for 180 tokens : 2.2222222222222223% similarity, with 4 matched token, and 176 token mismatch\n",
      "## Model validation for 190 tokens : 2.631578947368421% similarity, with 5 matched token, and 185 token mismatch\n",
      "## Model validation for 200 tokens : 2.5% similarity, with 5 matched token, and 195 token mismatch\n",
      "## Model validation for 210 tokens : 2.380952380952381% similarity, with 5 matched token, and 205 token mismatch\n",
      "## Model validation for 220 tokens : 2.272727272727273% similarity, with 5 matched token, and 215 token mismatch\n",
      "## Model validation for 230 tokens : 2.1739130434782608% similarity, with 5 matched token, and 225 token mismatch\n",
      "## Model validation for 240 tokens : 2.083333333333333% similarity, with 5 matched token, and 235 token mismatch\n",
      "## Model validation for 250 tokens : 2.0% similarity, with 5 matched token, and 245 token mismatch\n",
      "## Model validation for 260 tokens : 1.9230769230769231% similarity, with 5 matched token, and 255 token mismatch\n",
      "## Model validation for 270 tokens : 1.8518518518518516% similarity, with 5 matched token, and 265 token mismatch\n",
      "## Model validation for 280 tokens : 1.7857142857142856% similarity, with 5 matched token, and 275 token mismatch\n",
      "## Model validation for 290 tokens : 2.7586206896551726% similarity, with 8 matched token, and 282 token mismatch\n",
      "## Model validation for 300 tokens : 2.666666666666667% similarity, with 8 matched token, and 292 token mismatch\n",
      "## Model validation for 325 tokens : 2.1538461538461537% similarity, with 7 matched token, and 318 token mismatch\n",
      "## Model validation for 350 tokens : 2.0% similarity, with 7 matched token, and 343 token mismatch\n",
      "## Model validation for 375 tokens : 2.1333333333333333% similarity, with 8 matched token, and 367 token mismatch\n",
      "## Model validation for 400 tokens : 2.0% similarity, with 8 matched token, and 392 token mismatch\n",
      "## Model validation for 425 tokens : 1.8823529411764703% similarity, with 8 matched token, and 417 token mismatch\n",
      "## Model validation for 450 tokens : 1.7777777777777777% similarity, with 8 matched token, and 442 token mismatch\n",
      "## Model validation for 475 tokens : 1.6842105263157894% similarity, with 8 matched token, and 467 token mismatch\n",
      "## Model validation for 500 tokens : 1.7999999999999998% similarity, with 9 matched token, and 491 token mismatch\n",
      "## Model validation for 525 tokens : 1.7142857142857144% similarity, with 9 matched token, and 516 token mismatch\n",
      "## Model validation for 550 tokens : 1.8181818181818181% similarity, with 10 matched token, and 540 token mismatch\n",
      "## Model validation for 575 tokens : 1.7391304347826086% similarity, with 10 matched token, and 565 token mismatch\n",
      "## Model validation for 600 tokens : 1.6666666666666667% similarity, with 10 matched token, and 590 token mismatch\n",
      "## Model validation for 625 tokens : 1.76% similarity, with 11 matched token, and 614 token mismatch\n",
      "## Model validation for 650 tokens : 1.6923076923076923% similarity, with 11 matched token, and 639 token mismatch\n",
      "## Model validation for 675 tokens : 1.7777777777777777% similarity, with 12 matched token, and 663 token mismatch\n",
      "## Model validation for 700 tokens : 1.5714285714285716% similarity, with 11 matched token, and 689 token mismatch\n",
      "## Model validation for 750 tokens : 1.7333333333333332% similarity, with 13 matched token, and 737 token mismatch\n",
      "## Model validation for 800 tokens : 1.5% similarity, with 12 matched token, and 788 token mismatch\n",
      "## Model validation for 850 tokens : 1.7647058823529411% similarity, with 15 matched token, and 835 token mismatch\n",
      "## Model validation for 900 tokens : 1.6666666666666667% similarity, with 15 matched token, and 885 token mismatch\n",
      "## Model validation for 950 tokens : 1.789473684210526% similarity, with 17 matched token, and 933 token mismatch\n",
      "## Model validation for 1000 tokens : 1.9% similarity, with 19 matched token, and 981 token mismatch\n"
     ]
    }
   ],
   "source": [
    "# Lets do a quick memory test (let see if this behaviour is removed)\n",
    "!python3 ../memory_script/eval_model_memory_guided.py \"{PROJECT_DIR}/model/CodeShift-C-Memory-Parrot.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
