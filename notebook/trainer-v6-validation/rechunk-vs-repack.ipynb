{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing rechunking vs repacking training\n",
    "\n",
    "Starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENABLE_WANDB: True\n",
      "GPU_DEVICES: auto\n",
      "NOTEBOOK_DIR: /home/recursal/RWKV-infctx-trainer/notebook/trainer-v6-validation\n",
      "TRAINER_DIR: /home/recursal/RWKV-infctx-trainer/RWKV-v6\n",
      "PROJECT_DIR: /home/recursal/RWKV-infctx-trainer\n"
     ]
    }
   ],
   "source": [
    "GPU_DEVICES=\"auto\"\n",
    "ENABLE_WANDB=True\n",
    "WANDB_PREFIX=\"infctx-v6-validation\"\n",
    "\n",
    "print(\"ENABLE_WANDB:\", ENABLE_WANDB)\n",
    "print(\"GPU_DEVICES:\", GPU_DEVICES)\n",
    "\n",
    "if ENABLE_WANDB:\n",
    "    WANDB_MODE=\"online\"\n",
    "else:\n",
    "    WANDB_MODE=\"disabled\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v6/\"))\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-10 21:54:59,080] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "---- Initializing model ----\n",
      "No of layers: 6\n",
      "Embedding size: 1024\n",
      "Output model path: ../model/L6-D1024-world-v6base-init.pth\n",
      "Vocab size: 65536\n",
      "Emb scale: 0.0001\n",
      "Note: this process takes a significant time (and ram) for large models\n",
      "---- ----- ----\n",
      "Output model exists, skipping init_model\n"
     ]
    }
   ],
   "source": [
    "# Init the model\n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 ./init_model.py \\\n",
    "        --n_layer 6 --n_embd 1024 \\\n",
    "        --vocab_size world --skip-if-exists \\\n",
    "        \"../model/L6-D1024-world-v6base-init.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map (num_proc=160): 100%|â–ˆâ–ˆâ–ˆ| 1000000/1000000 [00:48<00:00, 20744.44 examples/s]\n",
      "Filter (num_proc=160): 100%|â–ˆ| 1000000/1000000 [00:06<00:00, 164014.77 examples/\n",
      "Map (num_proc=160): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134693/134693 [00:15<00:00, 8653.19 examples/s]\n",
      "Map (num_proc=160): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10020/10020 [00:12<00:00, 800.34 examples/s]\n",
      "Saving the dataset (4/4 shards): 100%|â–ˆ| 10020/10020 [00:12<00:00, 771.38 exampl\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 78.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Lets preload the requried dataset \n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 preload_datapath.py \"{NOTEBOOK_DIR}/config/enwiki_100k-world-32k-rechunk.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map (num_proc=160): 100%|â–ˆâ–ˆâ–ˆ| 1000000/1000000 [00:44<00:00, 22469.77 examples/s]\n",
      "Filter (num_proc=160): 100%|â–ˆ| 1000000/1000000 [00:06<00:00, 166543.29 examples/\n",
      "Map (num_proc=160): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134691/134691 [00:14<00:00, 9301.76 examples/s]\n",
      "Map (num_proc=160): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134691/134691 [00:19<00:00, 7044.24 examples/s]\n",
      "Saving the dataset (4/4 shards): 100%|â–ˆ| 10026/10026 [00:13<00:00, 716.74 exampl\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 80.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Lets preload the requried dataset \n",
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    python3 preload_datapath.py \"{NOTEBOOK_DIR}/config/enwiki_100k-world-32k-packing.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With rechunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-11 04:53:40,788] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py:518: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/trainer-v6-validation/config/enwiki_100k-world-32k-rechunk.yaml', '--model.load_model=../model/L6-D1024-world-v6base-init.pth', '--trainer.callbacks.init_args.dirpath=../checkpoint/v6-enwiki-32k-rechunk/', '--trainer.logger.init_args.name=infctx-v6-validation - Rechunk 32k - (deepspeed_stage_1)', '--trainer.strategy=deepspeed_stage_1', '--trainer.microbatch_size=4', '--trainer.devices=auto'], args=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/trainer-v6-validation/config/enwiki_100k-world-32k-rechunk.yaml', '--model.load_model=../model/L6-D1024-world-v6base-init.pth', '--trainer.callbacks.init_args.dirpath=../checkpoint/v6-enwiki-32k-rechunk/', '--trainer.logger.init_args.name=infctx-v6-validation - Rechunk 32k - (deepspeed_stage_1)', '--trainer.strategy=deepspeed_stage_1', '--trainer.microbatch_size=4', '--trainer.devices=auto'].\n",
      "Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       16\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             8\n",
      "   - microbatch_size:         4\n",
      "   - accumulate_grad_batches: 1\n",
      "   - effective_batch_size:    32\n",
      "\n",
      "[rank: 0] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "[2024-04-11 04:53:47,413] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 04:53:47,601] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 04:53:47,603] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 04:53:47,612] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 04:53:47,626] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 04:53:47,641] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 04:53:47,657] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[rank: 2] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 4] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 3] Seed set to 3941088705\n",
      "[rank: 1] Seed set to 3941088705\n",
      "[rank: 6] Seed set to 3941088705\n",
      "[rank: 7] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 5] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 2] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 4] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 1] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 3] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 5] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 6] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "[rank: 7] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-rechunk/\n",
      "Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicocreator\u001b[0m (\u001b[33mrwkv-x-dev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240411_045401-71g35wb7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33minfctx-v6-validation - Rechunk 32k - (deepspeed_stage_1)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-infctx-unit-test\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-infctx-unit-test/runs/71g35wb7\u001b[0m\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "#\n",
      "# RWKV lighting_trainer.py important notes \n",
      "# https://github.com/RWKV/RWKV-infctx-trainer \n",
      "#\n",
      "# - Ensure your host is not running cuda 12.0 (use either 11.8, or >=12.1), as this is known to have freeze issues\n",
      "# - The terms used in wandb / the progress bar can be confusing, see the github README.md for beter clarifications\n",
      "# - When resuming from checkpoint, the estimated time is inaccurate\n",
      "#LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  8.000e-04 (0.0008)\n",
      "    - lr_final: 3.000e-04 (0.0003)\n",
      "\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.06783437728881836 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10191011428833008 seconds\n",
      "Loading extension module fused_adam...\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...Loading extension module fused_adam...\n",
      "\n",
      "Time to load fused_adam op: 0.10303688049316406 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Time to load fused_adam op: 0.1030128002166748 seconds\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.1027231216430664 seconds\n",
      "Time to load fused_adam op: 0.10283923149108887 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10387253761291504 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Time to load fused_adam op: 0.10447454452514648 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 67.1 M\n",
      "1 | blocks | ModuleList | 84.6 M\n",
      "2 | ln_out | LayerNorm  | 2.0 K \n",
      "3 | head   | Linear     | 67.1 M\n",
      "--------------------------------------\n",
      "218 M     Trainable params\n",
      "0         Non-trainable params\n",
      "218 M     Total params\n",
      "875.446   Total estimated model params size (MB)\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:104: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "Epoch 0:  32%|â–‹ | 100/313 [11:48<25:09,  0.14it/s, v_num=5wb7, train/loss=5.250]/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Epoch 0: 100%|â–ˆâ–ˆ| 313/313 [36:52<00:00,  0.14it/s, v_num=5wb7, train/loss=4.500]`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "Epoch 0: 100%|â–ˆâ–ˆ| 313/313 [36:52<00:00,  0.14it/s, v_num=5wb7, train/loss=4.500]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.042 MB of 0.042 MB uploaded (0.003 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   batchidx â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      epoch â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                global_rank â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: perf/kTokens_per_sec.gpu.0 â–â–„â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   perf/kTokens_total.gpu.0 â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    substep â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/data_ctxlen â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/data_loss â–ˆâ–†â–…â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           train/learn_loss â–ˆâ–†â–…â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/learn_tokens â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/loss â–ˆâ–…â–ƒâ–‚â–‚â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      trainer/learning_rate â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   batchidx 312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      epoch 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                global_rank 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: perf/kTokens_per_sec.gpu.0 18.5517\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   perf/kTokens_total.gpu.0 41025.536\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                    substep 2496\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/data_ctxlen 32768.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            train/data_loss 4.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           train/learn_loss 4.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/learn_tokens 32768.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 train/loss 4.375\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        trainer/global_step 312\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      trainer/learning_rate 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33minfctx-v6-validation - Rechunk 32k - (deepspeed_stage_1)\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-infctx-unit-test/runs/71g35wb7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ï¸âš¡ View job at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-infctx-unit-test/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE2MTQwMDc3NQ==/version_details/v2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240411_045401-71g35wb7/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python3 lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/config/enwiki_100k-world-32k-rechunk.yaml\" \\\n",
    "        --model.load_model=\"../model/L6-D1024-world-v6base-init.pth\" \\\n",
    "        --trainer.callbacks.init_args.dirpath=\"../checkpoint/v6-enwiki-32k-rechunk/\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} - Rechunk 32k - (deepspeed_stage_1)\" \\\n",
    "        --trainer.strategy=\"deepspeed_stage_1\" \\\n",
    "        --trainer.microbatch_size=4 \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With dataset packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-11 05:49:37,197] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py:518: LightningCLI's args parameter is intended to run from within Python like if it were from the command line. To prevent mistakes it is not recommended to provide both args and command line arguments, got: sys.argv[1:]=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/trainer-v6-validation/config/enwiki_100k-world-32k-packing.yaml', '--model.load_model=../model/L6-D1024-world-v6base-init.pth', '--trainer.callbacks.init_args.dirpath=../checkpoint/v6-enwiki-32k-packing/', '--trainer.logger.init_args.name=infctx-v6-validation - Packing 32k - (deepspeed_stage_1)', '--trainer.strategy=deepspeed_stage_1', '--trainer.microbatch_size=4', '--trainer.devices=auto'], args=['fit', '-c', '/home/recursal/RWKV-infctx-trainer/notebook/trainer-v6-validation/config/enwiki_100k-world-32k-packing.yaml', '--model.load_model=../model/L6-D1024-world-v6base-init.pth', '--trainer.callbacks.init_args.dirpath=../checkpoint/v6-enwiki-32k-packing/', '--trainer.logger.init_args.name=infctx-v6-validation - Packing 32k - (deepspeed_stage_1)', '--trainer.strategy=deepspeed_stage_1', '--trainer.microbatch_size=4', '--trainer.devices=auto'].\n",
      "Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "\n",
      "[RWKV.Trainer] Applying 'target_batch_size' with the following:\n",
      "   - target_batch_size:       16\n",
      "   - num_nodes:               1\n",
      "   - num_devices:             8\n",
      "   - microbatch_size:         4\n",
      "   - accumulate_grad_batches: 1\n",
      "   - effective_batch_size:    32\n",
      "\n",
      "[rank: 0] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "[2024-04-11 05:49:43,941] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 05:49:43,977] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 05:49:44,003] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 05:49:44,066] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 05:49:44,075] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 05:49:44,107] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-04-11 05:49:44,204] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[RWKV.model] Running RWKV infctx using 'torch-jit' with torch '2.1.2'\n",
      "[rank: 6] Seed set to 3941088705\n",
      "[rank: 1] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 3] Seed set to 3941088705\n",
      "[rank: 7] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 4] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 2] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 5] Seed set to 3941088705\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "[rank: 6] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-packing/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-packing/\n",
      "[rank: 3] Seed set to 3941088705\n",
      "[rank: 1] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-packing/\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-packing/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-packing/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-packing/\n",
      "[rank: 4] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-packing/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-packing/\n",
      "[rank: 2] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-packing/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-packing/\n",
      "[rank: 5] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-packing/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-packing/\n",
      "[rank: 7] Seed set to 3941088705\n",
      "initializing deepspeed distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-packing/\n",
      ">> Loading dataset from data_path:  ../datapath/enwiki_100k-world-32k-packing/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-packing/\n",
      ">> Dataset load finished:  ../datapath/enwiki_100k-world-32k-packing/\n",
      "Enabling DeepSpeed BF16. Model parameters and inputs will be cast to `bfloat16`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpicocreator\u001b[0m (\u001b[33mrwkv-x-dev\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m./wandb/run-20240411_054958-uqsajemy\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33minfctx-v6-validation - Packing 32k - (deepspeed_stage_1)\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-infctx-unit-test\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/rwkv-x-dev/RWKV-infctx-unit-test/runs/uqsajemy\u001b[0m\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "#\n",
      "# RWKV lighting_trainer.py important notes \n",
      "# https://github.com/RWKV/RWKV-infctx-trainer \n",
      "#\n",
      "# - Ensure your host is not running cuda 12.0 (use either 11.8, or >=12.1), as this is known to have freeze issues\n",
      "# - The terms used in wandb / the progress bar can be confusing, see the github README.md for beter clarifications\n",
      "# - When resuming from checkpoint, the estimated time is inaccurate\n",
      "#LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "\n",
      "[RWKV.model] Configuring optimizer with\n",
      "    - lr_init:  8.000e-04 (0.0008)\n",
      "    - lr_final: 3.000e-04 (0.0003)\n",
      "\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "[WARNING]: unlimited bptt_learning_range across multiple GPU's has a performance penalty with datasets of mixed sizes due to its constant need to keep all GPU's in sync (consider using bptt_learning_range=1 instead)\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Using /home/recursal/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/recursal/.cache/torch_extensions/py311_cu121/fused_adam/build.ninja...\n",
      "Building extension module fused_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.06860780715942383 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10271430015563965 seconds\n",
      "Loading extension module fused_adam.../home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "\n",
      "Time to load fused_adam op: 0.10232329368591309 seconds\n",
      "Loading extension module fused_adam...\n",
      "Time to load fused_adam op: 0.10221076011657715 seconds\n",
      "Time to load fused_adam op: 0.102996826171875 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Time to load fused_adam op: 0.10257577896118164 seconds\n",
      "Time to load fused_adam op: 0.10251235961914062 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "Time to load fused_adam op: 0.10263323783874512 seconds\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/ops/adam/fused_adam.py:96: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400430266/work/torch/csrc/tensor/python_tensor.cpp:83.)\n",
      "  self._dummy_overflow_buf = get_accelerator().IntTensor([0])\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | emb    | Embedding  | 67.1 M\n",
      "1 | blocks | ModuleList | 84.6 M\n",
      "2 | ln_out | LayerNorm  | 2.0 K \n",
      "3 | head   | Linear     | 67.1 M\n",
      "--------------------------------------\n",
      "218 M     Trainable params\n",
      "0         Non-trainable params\n",
      "218 M     Total params\n",
      "875.446   Total estimated model params size (MB)\n",
      "/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:104: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "Epoch 0:   9%|â–Ž  | 29/314 [03:28<34:06,  0.14it/s, v_num=jemy, train/loss=6.310]Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 1341, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 1170, in compute_loss\n",
      "    segment_sample_loss, segment_train_loss, new_shift_states, new_wkv_states, segment_train_tokens = checkpointed_step(\n",
      "                                                                                                      ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 950, in checkpointed_step\n",
      "    logits, new_shift_states, new_wkv_states = self(\n",
      "                                               ^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 661, in forward\n",
      "    output_x, new_state = deepspeed_checkpoint(\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 21, in deepspeed_checkpoint\n",
      "    return deepspeed.checkpointing.checkpoint(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/lightning_trainer.py\", line 296, in <module>\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 994, in checkpoint\n",
      "    CheckpointFunction.apply(function, all_outputs, *args)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 539, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 565, in forward\n",
      "    outputs = run_function(*inputs_cuda)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 102, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/lightning_trainer.py\", line 271, in cli_main\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "RuntimeError: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/module/TimeMix.py\", line 211, in forward\n",
      "        \n",
      "        # Run without cuda (cpu mode, etc)\n",
      "        return self._forward_nocuda_optimized(x, last_state)\n",
      "               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/module/TimeMix.py\", line 265, in _forward_nocuda_optimized\n",
      "    def _forward_nocuda_optimized(self, x, last_state: tuple[torch.Tensor,torch.Tensor]) -> tuple[torch.Tensor,tuple[torch.Tensor,torch.Tensor]]:\n",
      "        shift_state_out = x[:,-1]\n",
      "                          ~~~~~~~ <--- HERE\n",
      "    \n",
      "        assert x.size(-2) % self.chunk_len == 0 or x.size(-2) == 1, \"optimized nocuda rwkv requires data len supplied to be an exact multiple of the chunk len\"\n",
      "RuntimeError: select(): index -1 out of range for tensor of size [4, 0, 1024] at dimension 1\n",
      "\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 1341, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 1170, in compute_loss\n",
      "    segment_sample_loss, segment_train_loss, new_shift_states, new_wkv_states, segment_train_tokens = checkpointed_step(\n",
      "                                                                                                      ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 950, in checkpointed_step\n",
      "    logits, new_shift_states, new_wkv_states = self(\n",
      "                                               ^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 661, in forward\n",
      "    output_x, new_state = deepspeed_checkpoint(\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 21, in deepspeed_checkpoint\n",
      "    return deepspeed.checkpointing.checkpoint(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 994, in checkpoint\n",
      "    CheckpointFunction.apply(function, all_outputs, *args)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 539, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 565, in forward\n",
      "    outputs = run_function(*inputs_cuda)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 102, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/module/TimeMix.py\", line 211, in forward\n",
      "        \n",
      "        # Run without cuda (cpu mode, etc)\n",
      "        return self._forward_nocuda_optimized(x, last_state)\n",
      "               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/module/TimeMix.py\", line 265, in _forward_nocuda_optimized\n",
      "    def _forward_nocuda_optimized(self, x, last_state: tuple[torch.Tensor,torch.Tensor]) -> tuple[torch.Tensor,tuple[torch.Tensor,torch.Tensor]]:\n",
      "        shift_state_out = x[:,-1]\n",
      "                          ~~~~~~~ <--- HERE\n",
      "    \n",
      "        assert x.size(-2) % self.chunk_len == 0 or x.size(-2) == 1, \"optimized nocuda rwkv requires data len supplied to be an exact multiple of the chunk len\"\n",
      "RuntimeError: select(): index -1 out of range for tensor of size [4, 0, 1024] at dimension 1\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/lightning_trainer.py\", line 296, in <module>\n",
      "    cli_main()\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/lightning_trainer.py\", line 271, in cli_main\n",
      "    LightningCLI(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 386, in __init__\n",
      "    self._run_subcommand(self.subcommand)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/cli.py\", line 677, in _run_subcommand\n",
      "    fn(**fn_kwargs)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 544, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 43, in _call_and_handle_interrupt\n",
      "    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/launchers/subprocess_script.py\", line 102, in launch\n",
      "    return function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 580, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 989, in _run\n",
      "    results = self._run_stage()\n",
      "              ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py\", line 1035, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 202, in run\n",
      "    self.advance()\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py\", line 359, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 136, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 240, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], batch_idx, kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 187, in run\n",
      "    self._optimizer_step(batch_idx, closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 265, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 157, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/module.py\", line 1291, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py\", line 151, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/ddp.py\", line 265, in optimizer_step\n",
      "    optimizer_output = super().optimizer_step(optimizer, closure, model, **kwargs)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 230, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/deepspeed.py\", line 123, in optimizer_step\n",
      "    closure_result = closure()\n",
      "                     ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 126, in closure\n",
      "    step_output = self._step_fn()\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 315, in _training_step\n",
      "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py\", line 309, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 381, in training_step\n",
      "    return self._forward_redirection(self.model, self.lightning_module, \"training_step\", *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 633, in __call__\n",
      "    wrapper_output = wrapper_module(*args, **kwargs)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/utils/nvtx.py\", line 15, in wrapped_fn\n",
      "    ret_val = func(*args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/engine.py\", line 1833, in forward\n",
      "    loss = self.module(*inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py\", line 626, in wrapped_forward\n",
      "    out = method(*_args, **_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 1341, in training_step\n",
      "    sampling_loss, training_loss = self.compute_loss(batch, batch_idx, True, False)\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 1170, in compute_loss\n",
      "    segment_sample_loss, segment_train_loss, new_shift_states, new_wkv_states, segment_train_tokens = checkpointed_step(\n",
      "                                                                                                      ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 950, in checkpointed_step\n",
      "    logits, new_shift_states, new_wkv_states = self(\n",
      "                                               ^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 661, in forward\n",
      "    output_x, new_state = deepspeed_checkpoint(\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 21, in deepspeed_checkpoint\n",
      "    return deepspeed.checkpointing.checkpoint(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 994, in checkpoint\n",
      "    CheckpointFunction.apply(function, all_outputs, *args)\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/autograd/function.py\", line 539, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py\", line 565, in forward\n",
      "    outputs = run_function(*inputs_cuda)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/model.py\", line 102, in forward\n",
      "    att_out, att_state = self.att(\n",
      "                         ^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/recursal/miniconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: The following operation failed in the TorchScript interpreter.\n",
      "Traceback of TorchScript (most recent call last):\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/module/TimeMix.py\", line 211, in forward\n",
      "        \n",
      "        # Run without cuda (cpu mode, etc)\n",
      "        return self._forward_nocuda_optimized(x, last_state)\n",
      "               ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n",
      "  File \"/home/recursal/RWKV-infctx-trainer/RWKV-v6/src/module/TimeMix.py\", line 265, in _forward_nocuda_optimized\n",
      "    def _forward_nocuda_optimized(self, x, last_state: tuple[torch.Tensor,torch.Tensor]) -> tuple[torch.Tensor,tuple[torch.Tensor,torch.Tensor]]:\n",
      "        shift_state_out = x[:,-1]\n",
      "                          ~~~~~~~ <--- HERE\n",
      "    \n",
      "        assert x.size(-2) % self.chunk_len == 0 or x.size(-2) == 1, \"optimized nocuda rwkv requires data len supplied to be an exact multiple of the chunk len\"\n",
      "RuntimeError: select(): index -1 out of range for tensor of size [4, 0, 1024] at dimension 1\n",
      "\n",
      "[rank: 1] Child process with PID 54815 terminated with code 1. Forcefully terminating all other processes to avoid zombies ðŸ§Ÿ\n"
     ]
    }
   ],
   "source": [
    "!cd \"{TRAINER_DIR}\" && \\\n",
    "    export WANDB_MODE=\"{WANDB_MODE}\" && \\\n",
    "    python3 lightning_trainer.py fit \\\n",
    "        -c \"{NOTEBOOK_DIR}/config/enwiki_100k-world-32k-packing.yaml\" \\\n",
    "        --model.load_model=\"../model/L6-D1024-world-v6base-init.pth\" \\\n",
    "        --trainer.callbacks.init_args.dirpath=\"../checkpoint/v6-enwiki-32k-packing/\" \\\n",
    "        --trainer.logger.init_args.name=\"{WANDB_PREFIX} - Packing 32k - (deepspeed_stage_1)\" \\\n",
    "        --trainer.strategy=\"deepspeed_stage_1\" \\\n",
    "        --trainer.microbatch_size=4 \\\n",
    "        --trainer.devices=\"{GPU_DEVICES}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv-infctx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
