{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of RWKV v5 model inference code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rwkv\n",
      "  Downloading rwkv-0.8.20-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from rwkv) (0.14.1)\n",
      "Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from tokenizers>=0.13.2->rwkv) (0.17.3)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->rwkv) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->rwkv) (2023.10.0)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->rwkv) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->rwkv) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->rwkv) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->rwkv) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->rwkv) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->rwkv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->rwkv) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->rwkv) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers>=0.13.2->rwkv) (2023.7.22)\n",
      "Downloading rwkv-0.8.20-py3-none-any.whl (400 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.8/400.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rwkv\n",
      "Successfully installed rwkv-0.8.20\n"
     ]
    }
   ],
   "source": [
    "# Update the RWKV pip package, found here : https://pypi.org/project/rwkv/\n",
    "!python3 -m pip install --upgrade rwkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTEBOOK_DIR: /home/ubuntu/rwkv-proj/RWKV-infctx-trainer/notebook/trainer-v5-validation\n",
      "TRAINER_DIR: /home/ubuntu/rwkv-proj/RWKV-infctx-trainer/RWKV-v5\n",
      "PROJECT_DIR: /home/ubuntu/rwkv-proj/RWKV-infctx-trainer\n"
     ]
    }
   ],
   "source": [
    "INFERENCE_MODE=\"cpu\"\n",
    "INFERENCE_TYPE=\"fp32\"\n",
    "\n",
    "# Computing the notebook, and various paths\n",
    "import os\n",
    "NOTEBOOK_DIR=os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_DIR=os.path.abspath(os.path.join(NOTEBOOK_DIR, \"../../\"))\n",
    "TRAINER_DIR=os.path.abspath(os.path.join(PROJECT_DIR, \"./RWKV-v5/\"))\n",
    "\n",
    "print(\"NOTEBOOK_DIR:\", NOTEBOOK_DIR)\n",
    "print(\"TRAINER_DIR:\", TRAINER_DIR)\n",
    "print(\"PROJECT_DIR:\", PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-05 05:40:27--  https://huggingface.co/BlinkDL/rwkv-5-world/resolve/8eb0273bd6935fa310c57532637d93d055d72f05/RWKV-5-World-1B5-v2-20231025-ctx4096.pth\n",
      "Resolving huggingface.co (huggingface.co)... 52.85.151.66, 52.85.151.16, 52.85.151.31, ...\n",
      "Connecting to huggingface.co (huggingface.co)|52.85.151.66|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/9b/0f/9b0f165daa456f007e672051275f10ff7862f8e2de07462884701e8f793c4518/5a89f56be7f82ab9dd0835af9a6838f788477471616c02f7b041e3aea0c57435?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27RWKV-5-World-1B5-v2-20231025-ctx4096.pth%3B+filename%3D%22RWKV-5-World-1B5-v2-20231025-ctx4096.pth%22%3B&Expires=1699422027&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5OTQyMjAyN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy85Yi8wZi85YjBmMTY1ZGFhNDU2ZjAwN2U2NzIwNTEyNzVmMTBmZjc4NjJmOGUyZGUwNzQ2Mjg4NDcwMWU4Zjc5M2M0NTE4LzVhODlmNTZiZTdmODJhYjlkZDA4MzVhZjlhNjgzOGY3ODg0Nzc0NzE2MTZjMDJmN2IwNDFlM2FlYTBjNTc0MzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=x7CERJkCSZvKrzMo8ihlghVT93qwMIUgav9A00dn%7E2SxtnAnAAyyvOxcg0oat1vIK6yEO%7E8cpkq8B%7Eww9n1xVIxSX-VjLsSxQCTfAhz5vnJL2DZkcv7BLFxBRvQq7r7fl%7Ehcp%7EEn-jKnzVdmoAM32WuDdhx-0om-T2PAcz53MP%7EcOQKJO8C1WwQADd22F04GAf2E0GX2IwqN0LEKNr1vqwPZLS7D7dCKwAby8KBFt0O5wEmZJeZaEoqahNo6CN1eWGs33IlOQHKdYAHE-nqyCdaDUYFgiyhBAHrLGujRnJyaFu21UlEv-QoUbqYur8dzdm5hXucGpFA3DqX2MmnPFw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2023-11-05 05:40:27--  https://cdn-lfs.huggingface.co/repos/9b/0f/9b0f165daa456f007e672051275f10ff7862f8e2de07462884701e8f793c4518/5a89f56be7f82ab9dd0835af9a6838f788477471616c02f7b041e3aea0c57435?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27RWKV-5-World-1B5-v2-20231025-ctx4096.pth%3B+filename%3D%22RWKV-5-World-1B5-v2-20231025-ctx4096.pth%22%3B&Expires=1699422027&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5OTQyMjAyN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy85Yi8wZi85YjBmMTY1ZGFhNDU2ZjAwN2U2NzIwNTEyNzVmMTBmZjc4NjJmOGUyZGUwNzQ2Mjg4NDcwMWU4Zjc5M2M0NTE4LzVhODlmNTZiZTdmODJhYjlkZDA4MzVhZjlhNjgzOGY3ODg0Nzc0NzE2MTZjMDJmN2IwNDFlM2FlYTBjNTc0MzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=x7CERJkCSZvKrzMo8ihlghVT93qwMIUgav9A00dn%7E2SxtnAnAAyyvOxcg0oat1vIK6yEO%7E8cpkq8B%7Eww9n1xVIxSX-VjLsSxQCTfAhz5vnJL2DZkcv7BLFxBRvQq7r7fl%7Ehcp%7EEn-jKnzVdmoAM32WuDdhx-0om-T2PAcz53MP%7EcOQKJO8C1WwQADd22F04GAf2E0GX2IwqN0LEKNr1vqwPZLS7D7dCKwAby8KBFt0O5wEmZJeZaEoqahNo6CN1eWGs33IlOQHKdYAHE-nqyCdaDUYFgiyhBAHrLGujRnJyaFu21UlEv-QoUbqYur8dzdm5hXucGpFA3DqX2MmnPFw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.138.64.111, 108.138.64.121, 108.138.64.36, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.138.64.111|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3155590194 (2.9G) [binary/octet-stream]\n",
      "Saving to: ‘RWKV-5-World-1B5-v2-20231025-ctx4096.pth’\n",
      "\n",
      "RWKV-5-World-1B5-v2 100%[===================>]   2.94G  46.2MB/s    in 66s     \n",
      "\n",
      "2023-11-05 05:41:33 (45.5 MB/s) - ‘RWKV-5-World-1B5-v2-20231025-ctx4096.pth’ saved [3155590194/3155590194]\n",
      "\n",
      "RWKV-5-World-1B5-v2-20231025-ctx4096.pth\n",
      "/home/ubuntu/rwkv-proj/RWKV-infctx-trainer/model\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ../../model/\n",
    "!cd ../../model/ && wget -nc \"https://huggingface.co/BlinkDL/rwkv-5-world/resolve/8eb0273bd6935fa310c57532637d93d055d72f05/RWKV-5-World-1B5-v2-20231025-ctx4096.pth\"\n",
    "!cd ../../model/ && ls\n",
    "!cd ../../model/ && pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference code inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RWKV_JIT_ON 1 RWKV_CUDA_ON 0 RESCALE_LAYER 0\n",
      "\n",
      "Loading /home/ubuntu/rwkv-proj/RWKV-infctx-trainer/model/RWKV-5-World-1B5-v2-20231025-ctx4096.pth ...\n",
      "Strategy: (total 24+1=25 layers)\n",
      "* cpu [float32, float32], store 25 layers\n",
      "0-cpu-float32-float32 1-cpu-float32-float32 2-cpu-float32-float32 3-cpu-float32-float32 4-cpu-float32-float32 5-cpu-float32-float32 6-cpu-float32-float32 7-cpu-float32-float32 8-cpu-float32-float32 9-cpu-float32-float32 10-cpu-float32-float32 11-cpu-float32-float32 12-cpu-float32-float32 13-cpu-float32-float32 14-cpu-float32-float32 15-cpu-float32-float32 16-cpu-float32-float32 17-cpu-float32-float32 18-cpu-float32-float32 19-cpu-float32-float32 20-cpu-float32-float32 21-cpu-float32-float32 22-cpu-float32-float32 23-cpu-float32-float32 24-cpu-float32-float32 \n",
      "emb.weight                        f32      cpu  65536  2048 \n",
      "blocks.0.ln1.weight               f32      cpu   2048       \n",
      "blocks.0.ln1.bias                 f32      cpu   2048       \n",
      "blocks.0.ln2.weight               f32      cpu   2048       \n",
      "blocks.0.ln2.bias                 f32      cpu   2048       \n",
      "blocks.0.att.time_mix_k           f32      cpu   2048       \n",
      "blocks.0.att.time_mix_v           f32      cpu   2048       \n",
      "blocks.0.att.time_mix_r           f32      cpu   2048       \n",
      "blocks.0.att.time_mix_g           f32      cpu   2048       \n",
      "blocks.0.att.time_decay           f32      cpu     32    64 \n",
      "blocks.0.att.time_first           f32      cpu     32    64 \n",
      "blocks.0.att.receptance.weight    f32      cpu   2048  2048 \n",
      "blocks.0.att.key.weight           f32      cpu   2048  2048 \n",
      "blocks.0.att.value.weight         f32      cpu   2048  2048 \n",
      "blocks.0.att.output.weight        f32      cpu   2048  2048 \n",
      "blocks.0.att.gate.weight          f32      cpu   2048  2048 \n",
      "blocks.0.att.ln_x.weight          f32      cpu   2048       \n",
      "blocks.0.att.ln_x.bias            f32      cpu   2048       \n",
      "blocks.0.ffn.time_mix_k           f32      cpu   2048       \n",
      "blocks.0.ffn.time_mix_r           f32      cpu   2048       \n",
      "blocks.0.ffn.key.weight           f32      cpu   2048  7168 \n",
      "blocks.0.ffn.receptance.weight    f32      cpu   2048  2048 \n",
      "blocks.0.ffn.value.weight         f32      cpu   7168  2048 \n",
      "....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "blocks.23.ln1.weight              f32      cpu   2048       \n",
      "blocks.23.ln1.bias                f32      cpu   2048       \n",
      "blocks.23.ln2.weight              f32      cpu   2048       \n",
      "blocks.23.ln2.bias                f32      cpu   2048       \n",
      "blocks.23.att.time_mix_k          f32      cpu   2048       \n",
      "blocks.23.att.time_mix_v          f32      cpu   2048       \n",
      "blocks.23.att.time_mix_r          f32      cpu   2048       \n",
      "blocks.23.att.time_mix_g          f32      cpu   2048       \n",
      "blocks.23.att.time_decay          f32      cpu     32    64 \n",
      "blocks.23.att.time_first          f32      cpu     32    64 \n",
      "blocks.23.att.receptance.weight   f32      cpu   2048  2048 \n",
      "blocks.23.att.key.weight          f32      cpu   2048  2048 \n",
      "blocks.23.att.value.weight        f32      cpu   2048  2048 \n",
      "blocks.23.att.output.weight       f32      cpu   2048  2048 \n",
      "blocks.23.att.gate.weight         f32      cpu   2048  2048 \n",
      "blocks.23.att.ln_x.weight         f32      cpu   2048       \n",
      "blocks.23.att.ln_x.bias           f32      cpu   2048       \n",
      "blocks.23.ffn.time_mix_k          f32      cpu   2048       \n",
      "blocks.23.ffn.time_mix_r          f32      cpu   2048       \n",
      "blocks.23.ffn.key.weight          f32      cpu   2048  7168 \n",
      "blocks.23.ffn.receptance.weight   f32      cpu   2048  2048 \n",
      "blocks.23.ffn.value.weight        f32      cpu   7168  2048 \n",
      "ln_out.weight                     f32      cpu   2048       \n",
      "ln_out.bias                       f32      cpu   2048       \n",
      "head.weight                       f32      cpu   2048 65536 \n",
      "------\n",
      "\n",
      "In a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\n",
      "The researchers, who were led by Dr. David Doubilet, a photographer, were able to capture the dragons in their natural habitat.\n",
      "The dragons were found in the remote valley of the Himalayas, in the Tibetan Plateau. The valley is located in the province of Qinghai, in the northwestern part of China.\n",
      "The valley is home to a large population of Tibetan antelopes, which are known for their unique horns.\n",
      "The researchers were able to capture the dragons in their natural habitat, using a camera mounted on a drone.\n",
      "The footage was then edited and turned into a short film, which was released in 2016.\n",
      "The footage was also used in a documentary about the dragons, which was released in 2017.\n",
      "The footage was also used in a documentary about the dragons, which was released in 2017.\n",
      "The footage was also used in a documentary about the dragons, which was released in 2017.\n",
      "The footage was also used"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['RWKV_JIT_ON'] = '1'\n",
    "os.environ[\"RWKV_CUDA_ON\"] = '0' # '1' to compile CUDA kernel (10x faster), requires c++ compiler & cuda libraries\n",
    "\n",
    "import torch\n",
    "from rwkv.model import RWKV\n",
    "# from rwkv.utils import PIPELINE, PIPELINE_ARGS\n",
    "from rwkv.rwkv_tokenizer import TRIE_TOKENIZER\n",
    "\n",
    "# Tokenizer setup\n",
    "PROMPT_STR = \"\\nIn a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\"\n",
    "WORLD_TOKENIZER = TRIE_TOKENIZER(TRAINER_DIR + '/src/dataflow/rwkv_vocab_v20230424.txt')        \n",
    "PROMPT_TOKENS = WORLD_TOKENIZER.encode(PROMPT_STR)\n",
    "LENGTH=200\n",
    "\n",
    "# Load the model\n",
    "MODEL = RWKV(model=os.path.join(PROJECT_DIR, \"model/RWKV-5-World-1B5-v2-20231025-ctx4096.pth\"), strategy='cpu fp32')\n",
    "\n",
    "# Build the baseline state\n",
    "LOGITS, STATE = MODEL.forward(PROMPT_TOKENS, None)\n",
    "TOKEN_ID = torch.argmax(LOGITS, dim=-1).item()\n",
    "\n",
    "# Print the prompt prefix\n",
    "print(\"------\")\n",
    "print(PROMPT_STR, end='')\n",
    "print(WORLD_TOKENIZER.decode([\n",
    "    TOKEN_ID\n",
    "]), end='', flush=True)\n",
    "\n",
    "# And get the next LENGTH tokens\n",
    "for i in range(LENGTH-1):\n",
    "    LOGITS, STATE = MODEL.forward([TOKEN_ID], STATE)\n",
    "    TOKEN_ID = torch.argmax(LOGITS, dim=-1).item()\n",
    "\n",
    "    print(WORLD_TOKENIZER.decode([\n",
    "        TOKEN_ID\n",
    "    ]), end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected result should be\n",
    "\n",
    "```\n",
    "\n",
    "The researchers, who were led by Dr. David Doubilet, a photographer, were able to capture the dragons in their natural habitat.\n",
    "The dragons were found in the remote valley of the Himalayas, in the Tibetan Plateau. The valley is located in the province of Qinghai, in the northwestern part of China.\n",
    "The valley is home to a large population of Tibetan antelopes, which are known for their unique horns.\n",
    "The researchers were able to capture the dragons in their natural habitat, using a camera mounted on a drone.\n",
    "The footage was then edited and turned into a short film, which was released in 2016.\n",
    "The footage was also used in a documentary about the dragons, which was released in 2017.\n",
    "The footage was also used in a documentary about the dragons, which was released in 2017.\n",
    "The footage was also used in a documentary about the dragons, which was released in 2017.\n",
    "The footage was also used\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RWKV infctx trainer, in inference mode\n",
    "\n",
    "Should match the above result (200 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-05 06:23:52,737] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[RWKV.model] Running RWKV model using 'torch-jit' with torch '2.1.0'\n",
      "/home/ubuntu/anaconda3/envs/rwkv-infctx/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/ubuntu/rwkv-proj/RWKV-infctx-trainer/RWKV-v5/src/model.py:1421: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch_tokens = torch.tensor(\n",
      "--- DRAGON PROMPT (REF RUN) ---\n",
      "In a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\n",
      "The researchers, who were led by Dr. David Doubilet, a photographer, were able to capture the dragons in their natural habitat.\n",
      "The dragons were found in the remote valley of the Himalayas, in the Tibetan Plateau. The valley is located in the province of Qinghai, in the northwestern part of China.\n",
      "The valley is home to a large population of Tibetan antelopes, which are known for their unique horns.\n",
      "The researchers were able to capture the dragons in their natural habitat, using a camera mounted on a drone.\n",
      "The footage was then edited and turned into a short film, which was released in 2016.\n",
      "The footage was also used in a documentary about the dragons, which was released in 2017.\n",
      "The footage was also used in a documentary about the dragons, which was released in 2017.\n",
      "The footage was also used in a documentary about the dragons, which was released in 2017.\n",
      "The footage was also used\n"
     ]
    }
   ],
   "source": [
    "# Run the reference implementation\n",
    "!cd $TRAINER_DIR && python3 ./dragon_test.py \"../model/RWKV-5-World-1B5-v2-20231025-ctx4096.pth\" \"ref\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwkv-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
